---
title: "Child Marriage Phenomenon In Vietnam"
author: "Holly Duong"
date: "2024-02-29"
output:
  word_document: default
  pdf_document: default
  always_allow_html: true
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE}
# load packages
library(readr)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(corrplot)
library(plotly)
library(reshape2)
library(car)
library(kableExtra)
library(broom)
library(knitr)
library(pROC)
library(ggpattern)
library(tidyr)
library(ResourceSelection)
library(sf)
```

### Setting up Data

```{r message=FALSE, warning=FALSE}
# import dataset
female <- read_csv("/Users/hollyduong/Desktop/DA 401/ChildMarriageInVietnam/Data/wm.csv")
```

```{r}
# get a glimpse of dataset
head(female)
```

```{r}
# Select the specified columns to create a new dataframe
female_df <- select(female, WAGEM, MSTATUS, HH6, HH7, welevel, insurance, ethnicity, windex5, CP2, HA1, MT4, MT9, MT11)

# View the first few rows of the new dataframe
summary(female_df)
```

```{r}
# Rename the columns
female_df <- female_df %>%
  rename(
  age_first_marriage = WAGEM,
  marital_status = MSTATUS,
  area = HH6,
  region = HH7,
  education_level = welevel,
  health_insurance = insurance,
  ethnicity = ethnicity,
  wealth_index = windex5,
  current_contraceptive_use = CP2,
  awareness_hiv_aids = HA1,
  used_computer_tablet = MT4,
  used_internet = MT9,
  owns_mobile_phone = MT11
)
```

```{r}
# Summarize missing values by column
summarize_missing <- sapply(female_df, function(x) sum(is.na(x)))
print(summarize_missing)
```

```{r}
# Recode the value 9 to NA for specified variables
female_df <- female_df %>%
  mutate(
    current_contraceptive_use = na_if(current_contraceptive_use, 9),
    used_internet = na_if(used_internet, 9),
    health_insurance = na_if(health_insurance, 9),
    education_level = na_if(education_level, 9),
    awareness_hiv_aids = na_if(awareness_hiv_aids, 9),
    used_computer_tablet = na_if(used_computer_tablet, 9),
    owns_mobile_phone = na_if(owns_mobile_phone, 9),
    marital_status = na_if(marital_status, 9)
  )

# Recode the value 6 to NA for 'ethnicity'
female_df$ethnicity <- na_if(female_df$ethnicity, 6)

# Recode the value 0 to NA for 'wealth_index'
female_df$wealth_index <- na_if(female_df$wealth_index, 0)
```

```{r}
# Recoding variables from 1 (Yes) and 2 (No) to 1 (Yes) and 0 (No)
female_df$health_insurance <- ifelse(female_df$health_insurance == 2, 0, female_df$health_insurance)
female_df$current_contraceptive_use <- ifelse(female_df$current_contraceptive_use == 2, 0, female_df$current_contraceptive_use)
female_df$awareness_hiv_aids <- ifelse(female_df$awareness_hiv_aids == 2, 0, female_df$awareness_hiv_aids)
female_df$used_computer_tablet <- ifelse(female_df$used_computer_tablet == 2, 0, female_df$used_computer_tablet)
female_df$owns_mobile_phone <- ifelse(female_df$owns_mobile_phone == 2, 0, female_df$owns_mobile_phone)
female_df$used_internet <- ifelse(female_df$used_internet == 2, 0, female_df$used_internet)
```

```{r}
# View the changes to ensure NA substitution has been correctly applied
summary(female_df)
```

### Creating New Variable `Access to Media`

```{r}
# Combine individual variables for access to the internet, phone, and computer into a single variable
# This new variable "access_to_media" will have a value of 1 if the respondent has access to any of these media sources, and 0 if not
# This provides a more comprehensive measure of media access
female_df <- female_df %>%
  mutate(access_to_media = ifelse(used_computer_tablet == 1 | used_internet == 1 | owns_mobile_phone == 1, 1, 0))

# In later analysis, use access_to_media instead of the 3 separate variables
```

```{r}
# Exporting female_df to a CSV file in the current working directory
#write.csv(female_df, "female_df.csv", row.names = FALSE)
```

### Distributions of Data

```{r}
# Histogram for 'Age at First Marriage'
afm_hist <- ggplot(female_df, aes(x = age_first_marriage)) +
  geom_histogram(fill = "#F7C0C8", color = "black") +
  theme_minimal() +
  ggtitle("Histogram of Age at First Marriage") +
  xlab("Age at First Marriage") +
  ylab("Frequency")

print(afm_hist)
```


### Handling Missing Data

```{r}
# Before that, let's double check the count of missing values by column
count_missing <- sapply(female_df, function(x) sum(is.na(x)))
print(count_missing)
```

```{r}
# Make a copy of female_df for imputation
imputed_df <- female_df
```

```{r}
# Handle missing values in 'Age at First Marriage'

# Calculate the median value for 'Age at First Marriage', excluding NA values
median_age_first_marriage <- median(imputed_df$age_first_marriage, na.rm = TRUE)

# Impute missing values in 'Age at First Marriage' with the median value
imputed_df$age_first_marriage[is.na(imputed_df$age_first_marriage)] <- median_age_first_marriage
```

```{r}
# Define a function to calculate mode for categorical variables
getMode <- function(v) {
  # The mode is the value that appears most frequently in the data
  uniqv <- unique(na.omit(v))  # Omit NA values and get unique values
  uniqv[which.max(tabulate(match(v, uniqv)))]  # Return the value with the highest frequency
}
```

```{r}
# For 'ethnicity', an ordinal variable with predefined categories, it makes sense to impute missing values with the mode.
mode_ethnicity <- getMode(imputed_df$ethnicity)
imputed_df <- mutate(imputed_df, ethnicity = ifelse(is.na(ethnicity), mode_ethnicity, ethnicity))
mode_area <- getMode(imputed_df$area)
imputed_df <- mutate(imputed_df, area = ifelse(is.na(area), mode_area, area))
mode_region <- getMode(imputed_df$region)
imputed_df <- mutate(imputed_df, region = ifelse(is.na(region), mode_region, region))
mode_marital_status <- getMode(imputed_df$marital_status)
imputed_df <- mutate(imputed_df, marital_status = ifelse(is.na(marital_status), mode_marital_status, marital_status))


# Binary variables like 'current_contraceptive_use', 'health_insurance','awareness_hiv_aids', 'used_internet', 'used_computer_tablet', 'owns_mobile_phone', and 'access_to_media'
# should be imputed with the mode since it represents the most frequent category (either 0 or 1).

# Calculate the mode for each binary variable
mode_used_internet <- getMode(imputed_df$used_internet)
mode_current_contraceptive_use <- getMode(imputed_df$current_contraceptive_use)
mode_health_insurance <- getMode(imputed_df$health_insurance)
mode_awareness_hiv_aids <- getMode(imputed_df$awareness_hiv_aids)
mode_used_computer_tablet <- getMode(imputed_df$used_computer_tablet)
mode_owns_mobile_phone <- getMode(imputed_df$owns_mobile_phone)
mode_access_to_media <- getMode(imputed_df$access_to_media)

# Impute missing values for binary variables
imputed_df <- mutate(imputed_df,
  used_internet = ifelse(is.na(used_internet), mode_used_internet, used_internet),
  current_contraceptive_use = ifelse(is.na(current_contraceptive_use), mode_current_contraceptive_use, current_contraceptive_use),
  health_insurance = ifelse(is.na(health_insurance), mode_health_insurance, health_insurance),
  awareness_hiv_aids = ifelse(is.na(awareness_hiv_aids), mode_awareness_hiv_aids, awareness_hiv_aids),
  used_computer_tablet = ifelse(is.na(used_computer_tablet), mode_used_computer_tablet, used_computer_tablet),
  owns_mobile_phone = ifelse(is.na(owns_mobile_phone), mode_owns_mobile_phone, owns_mobile_phone),
  access_to_media = ifelse(is.na(access_to_media), mode_access_to_media, access_to_media)
)

# 'education_level' is an ordinal variable where the median could be a more suitable measure of central tendency than the mode.
# However, given the categorical nature of the levels (e.g., "Primary", "Secondary"), using the mode may still be appropriate.
mode_education_level <- getMode(imputed_df$education_level)
imputed_df <- mutate(imputed_df, education_level = ifelse(is.na(education_level), mode_education_level, education_level))

# 'wealth_index' is an ordinal variable where the median could be a more suitable measure of central tendency than the mode.
# However, given the categorical nature of the levels (e.g., "Poorest", "Poor",...), using the mode may still be appropriate.
mode_wealth_index <- getMode(imputed_df$wealth_index)
imputed_df <- mutate(imputed_df, wealth_index = ifelse(is.na(wealth_index), mode_wealth_index, wealth_index))
```


```{r}
# Check the resulting dataset to confirm changes
summary(imputed_df)
```

```{r}
# After imputation, let's check for missing values
count_imputation <- sapply(imputed_df, function(x) sum(is.na(x)))
print(count_imputation)
```

### Visualization Comparing Before vs. After Imputation

```{r}
# Histogram for 'age_first_marriage' before imputation
afm_0 <- ggplot(female_df, aes(x = age_first_marriage)) + 
  geom_histogram(fill = "#F7C0C8", color = "black", bins = 30) +
  theme_light() +
  ggtitle("Before Imputation") +
  xlab("Age at First Marriage") +
  ylab("Frequency")

# Histogram for 'age_first_marriage' after imputation
afm_imputed <- ggplot(imputed_df, aes(x = age_first_marriage)) + 
  geom_histogram(fill = "#E83853", color = "black", bins = 30) +
  theme_light() +
  ggtitle("After Imputation") +
  xlab("Age at First Marriage") +
  ylab("Frequency")

# Arrange the two plots side by side
grid.arrange(afm_0, afm_imputed, ncol = 2)
```

```{r}
# Arrange the two plots side by side and capture the layout as a grob
combined_plots <- arrangeGrob(afm_0, afm_imputed, ncol = 2)

# Now, use ggsave to save the combined plot
#ggsave("combined_age_first_marriage.png", plot = combined_plots, width = 10, height = 5)
```

### Creating Binary Variables for Child Marriage Under 18 and 16

```{r}
# Convert "age at first marriage" into a binary variable to indicate child marriage
# Child marriage is defined as marriage before the age of 18
# The new binary variable "child_marriage" will have a value of 1 if the marriage occurred before age 18, and 0 otherwise
imputed_df <- imputed_df %>%
  mutate(child_marriage = ifelse(age_first_marriage < 18, 1, 0))
```

```{r}
# Create a binary variable for child marriage under 16
# The new variable "child_marriage_u16" will have a value of 1 if the marriage occurred before age 16, and 0 otherwise
imputed_df <- imputed_df %>%
  mutate(child_marriage_u16 = ifelse(age_first_marriage < 16, 1, 0))
```

```{r}
# Move "child_marriage" and "child_marriage_u16" to the front of the dataframe
imputed_df <- imputed_df %>%
  select(child_marriage, child_marriage_u16, everything())
```

```{r}
# Exporting female_df to a CSV file in the current working directory
#write.csv(imputed_df, "imputed_df.csv", row.names = FALSE)
```

### EDA

#### Vietnam Map with Regions and Their Percentages of Child Marriage (under 18)

```{r}
# Aggregate the data by region to get the total number of child marriages under 18 per region
region_counts <- aggregate(child_marriage ~ region, data = imputed_df, FUN = sum)

# Calculate the total number of child marriages under 18 in the dataset
total_child_marriages <- sum(region_counts$child_marriage)

# Calculate the percentage for each region
region_counts$married_u18_perc_of_total <- (region_counts$child_marriage / total_child_marriages) * 100
```

```{r}
# Mapping region numbers to names
region_names <- c("Red River Delta", "Northern Midlands And Mountain", 
                  "North Central And Central Coastal", "Central Highlands", 
                  "South East", "Mekong River Delta")
names(region_counts)[1] <- "region_name"
region_counts$region_name <- factor(region_counts$region_name, levels = 1:6, labels = region_names)

# Display the final data frame
print(region_counts)
```


```{r}
# Updated mapping including all provinces and cities in the Red River Delta
province_to_region <- data.frame(
  NAME_1 = c(
    'Bắc Ninh', 'Hà Nam', 'Hà Nội', 'Hải Dương', 'Hải Phòng', 'Hoà Bình', 'Hưng Yên', 'Nam Định', 'Ninh Bình', 'Thái Bình', 'Vĩnh Phúc', # Red River Delta 11
    
    'Bắc Giang', 'Bắc Kạn', 'Cao Bằng', 'Hà Giang', 'Lạng Sơn', 'Lào Cai', 'Phú Thọ', 'Quảng Ninh', 'Thái Nguyên', 'Tuyên Quang', 'Yên Bái', 'Điện Biên', 'Lai Châu', 'Sơn La', # Northern Midlands And Mountain 14
    
    'Bình Định', 'Bình Thuận', 'Khánh Hòa', 'Ninh Thuận', 'Phú Yên', 'Quảng Nam', 'Quảng Ngãi', 'Thừa Thiên Huế', 'Đà Nẵng', 'Hà Tĩnh', 'Nghệ An', 'Quảng Bình', 'Quảng Trị', 'Thanh Hóa', # North Central And Central Coastal 14
    
    'Đắk Lắk', 'Đắk Nông', 'Gia Lai', 'Kon Tum', 'Lâm Đồng', # Central Highlands 5
    
    'Bà Rịa - Vũng Tàu', 'Bình Dương', 'Bình Phước', 'Đồng Nai', 'Hồ Chí Minh', 'Tây Ninh', # South East 6
    
    'An Giang', 'Bạc Liêu', 'Bến Tre', 'Cà Mau', 'Cần Thơ', 'Đồng Tháp', 'Hậu Giang', 'Kiên Giang', 'Long An', 'Sóc Trăng', 'Tiền Giang', 'Trà Vinh', 'Vĩnh Long' # Mekong River Delta 13
  ),
  Region = c(
    rep('Red River Delta', 11), 
    rep('Northern Midlands And Mountain', 14), 
    rep('North Central And Central Coastal', 14), 
    rep('Central Highlands', 5), 
    rep('South East', 6), 
    rep('Mekong River Delta', 13)
  )
)

```


```{r}
# Check the mapping
#print(province_to_region)
```


```{r message=FALSE, warning=FALSE}
# Read shapefile
vietnam_shape <- st_read('/Users/hollyduong/Desktop/DA 401/ChildMarriageInVietnam/gadm41_VNM_shp')

# Join the shapefile with the province-to-region mapping
vietnam_shape_with_region <- vietnam_shape %>%
  left_join(province_to_region, by = "NAME_1")

# Aggregate the shapefile data by region
vietnam_regions <- vietnam_shape_with_region %>%
  group_by(Region) %>%
  summarise(geometry = st_union(geometry), .groups = 'drop')
```


```{r}
# Join the aggregated shapefile data with the child marriage data
vietnam_map_data <- vietnam_regions %>%
  left_join(region_counts, by = c("Region" = "region_name"))

# Define colors with your specific choices
colors_ordered <- setNames(c("#B20033", "#CD0A25", "#E83853", "#EF7D8D", "#F7C0C8", "#FBE1E5"),
                           c("Northern Midlands And Mountain", "Central Highlands", 
                             "Mekong River Delta", "North Central And Central Coastal", 
                             "South East", "Red River Delta"))

# Plot
mapvn <- ggplot(data = vietnam_map_data) +
  geom_sf(aes(fill = factor(Region, levels = names(colors_ordered))), color = NA) +
  geom_sf_text(aes(label = sprintf("%.1f%%", married_u18_perc_of_total)), size = 4, hjust = 0.5, vjust = 0.5) +
  scale_fill_manual(values = colors_ordered, name = "Region") +
  labs(title = "Regional Contribution of Female Child Marriage Rates to Total Rates in Vietnam") +
  theme_void() +
  theme(legend.position = "right")

print(mapvn)
```

```{r}
#ggsave("mapvn.png", plot = mapvn, width = 8, height = 6, dpi = 300)
```

#### Marital Status Among Female Respondants by Region in Vietnam

```{r}
# Calculate total observations
total_obs <- nrow(imputed_df)

# Aggregate counts for each category by region without altering the original 'region' field
counts_df <- aggregate(cbind(ever_married = imputed_df$marital_status %in% c(1, 2), 
                             married_u18 = imputed_df$child_marriage == 1, 
                             married_u16 = imputed_df$child_marriage_u16 == 1) ~ region, 
                       data = imputed_df, 
                       FUN = sum)

# Convert counts to percentages
counts_df$ever_married <- (counts_df$ever_married / total_obs) * 100
counts_df$married_u18 <- (counts_df$married_u18 / total_obs) * 100
counts_df$married_u16 <- (counts_df$married_u16 / total_obs) * 100
```


```{r}
p <- ggplot(counts_df, aes(x = factor(region))) +
  geom_bar(aes(y = ever_married, fill = "Ever married"), stat = "identity") +
  geom_bar(aes(y = married_u18, fill = "Married before 18 years old"), stat = "identity") +
  geom_bar(aes(y = married_u16, fill = "Married before 16 years old"), stat = "identity") +
  # Adding text labels for ever_married
  geom_text(aes(y = ever_married, label = sprintf("%.1f%%", ever_married)), 
            position = position_stack(vjust = 1.025), 
            size = 4, color = "black") +
  # Adding text labels for married_u18
  geom_text(aes(y = married_u18, label = sprintf("%.1f%%", married_u18)), 
            position = position_stack(vjust = 1.05), 
            size = 4, color = "black") +
  # Adding text labels for married_u16
  geom_text(aes(y = married_u16, label = sprintf("%.1f%%", married_u16)), 
            position = position_stack(vjust = 1.1), 
            size = 4, color = "black") +
  scale_fill_manual(values = c("Ever married" = "#FBE1E5", 
                               "Married before 18 years old" = "#EF7D8D", 
                               "Married before 16 years old" = "#B20016"),
                    name = "Marital Status") +
  labs(x = "Region", y = "Percentage", title = "Marital Status Among Female Respondants by Region") +
  theme_minimal() +
  theme(plot.margin = margin(t = 10, r = 10, b = 10, l = 10, unit = "mm"), 
        axis.text.x = element_text(angle = 45, hjust = 1), 
        legend.position = "right") +
  scale_x_discrete(labels = c("1" = "Red River Delta", "2" = "Northern Midlands And Mountain", 
                              "3" = "North Central And Central Coastal", "4" = "Central Highlands", 
                              "5" = "South East", "6" = "Mekong River Delta"))

# Convert ggplot object to plotly for interactive visualization
ggplotly(p)
```



### Preparing for Regression Analysis

#### Correlation Matrix

```{r}
# Calculate correlation matrix
cor_matrix <- cor(imputed_df %>% select_if(is.numeric), use = "complete.obs")

# Melt the correlation matrix
melted_cor_matrix <- melt(cor_matrix)
```

```{r}
# Generate an interactive heatmap
corr_matrix <- ggplot(melted_cor_matrix, aes(Var1, Var2, fill = value)) +
    geom_tile() +
    scale_fill_gradientn(
        colours = c("deepskyblue", "white", "#CD0A25"),
        values = scales::rescale(c(-1, 0, 1)),
        limits = c(-1, 1),
        name="Pearson\nCorrelation"
    ) +
    theme_minimal() + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    xlab("") + 
    ylab("") +
    ggtitle("Correlation Matrix") 

# Convert ggplot object to plotly for interactivity
ggplotly(corr_matrix)
```



#### Converting Categorical and Binary Variables to Factors


```{r}
# Convert nominal and ordinal variables to factors
imputed_df$area <- as.factor(imputed_df$area)
imputed_df$region <- as.factor(imputed_df$region)
imputed_df$education_level <- factor(imputed_df$education_level, ordered = FALSE)
imputed_df$ethnicity <- as.factor(imputed_df$ethnicity)
imputed_df$wealth_index <- factor(imputed_df$wealth_index, ordered = FALSE)

# Binary variables are already in the correct format and can be used as is
```

### Base Logistic Regression Model

```{r}
# Baseline model for reference
baseline_model <- glm(child_marriage ~ area + education_level + wealth_index + health_insurance + current_contraceptive_use + awareness_hiv_aids + access_to_media, family = binomial(), data = imputed_df)

# Summarize the baseline model
summary(baseline_model)
```

#### Accessing Base Model's Multicollinearity

```{r}
# Calculate VIF (A VIF value > 5 indicates high multicollinearity)
base_vif_results <- vif(baseline_model)
print(base_vif_results)

# Check if any VIF value is greater than a typical threshold, like 5 or 10.
base_high_vif <- base_vif_results[base_vif_results > 5]
print(base_high_vif)
```

### Adding Fixed Effects to Base Model

```{r}
# Enhanced model with additional fixed effects
enhanced_model <- glm(child_marriage ~ area + region + education_level + ethnicity + wealth_index + health_insurance + current_contraceptive_use + awareness_hiv_aids + access_to_media, 
                      family = binomial(), 
                      data = imputed_df)

# Summarize the new model with FEs
summary(enhanced_model)
```

#### Model with FEs' Multicollinearity

```{r}
# Calculate VIF (A VIF value > 5 indicates high multicollinearity)
FE_vif_results <- vif(enhanced_model)
print(FE_vif_results)

# Check if any VIF value is greater than a typical threshold, like 5.
FE_high_vif <- FE_vif_results[FE_vif_results > 5]
print(FE_high_vif)
```

No VIF is significant larger than 5. This suggests that the independent variables in my model with Fixed Effects do not suffer from severe multicollinearity. 

#### Assessing AICs and BICs of Base Model vs Fixed Effects Model

```{r}
# Model comparison using AIC
aic_base <- AIC(baseline_model)
aic_enhanced <- AIC(enhanced_model)
cat("AIC - Base Model:", aic_base, "\n")
cat("AIC - Enhanced Model:", aic_enhanced, "\n")
```

Additionally, the lower AIC for the model with two fixed effects compared to the baseline model suggests that adding these fixed effects improves the model's overall fit. This aligns with my theoretical justification for including region and ethnicity as relevant factors in predicting child marriage.

```{r}
# Model comparison using BIC
bic_base <- BIC(baseline_model)
bic_enhanced <- BIC(enhanced_model)
cat("BIC - Base Model:", bic_base, "\n")
cat("BIC - Enhanced Model:", bic_enhanced, "\n")
```

Lower BIC values suggest that, despite the added complexity (more parameters), the model with both region and ethnicity provides a better overall fit to my data when adjusted for the number of predictors. This is a strong indication that these variables are meaningful in explaining the variance in child marriage occurrences in my dataset.


### Model with Interaction Terms (Area:Wealth_Index)

```{r}
# Adding the interaction term between education level and wealth index
model_interaction <- update(enhanced_model, . ~ . + area:wealth_index)
summary(model_interaction)
```

#### Assessing AICs and BICs of Fixed Effects Model vs Fixed Effects Model w/ Interaction Terms

```{r}
cat("AIC (enhanced):", AIC(enhanced_model), "\nAIC (w/ interaction terms):", AIC(model_interaction), "\n")
cat("BIC (enhanced):", BIC(enhanced_model), "\nBIC (w/ interaction terms):", BIC(model_interaction), "\n")
```

- The AIC and BIC results for my two models – the `enhanced_model` and `model_interaction` – indicate that the simpler model (without interaction terms) has a better trade-off between model fit and complexity.
- The AIC is lower for the enhanced_model compared to the `model_interaction`. This suggests that, despite possibly having a good fit, the addition of interaction terms to the `model_interaction` does not improve the model's performance enough to justify the added complexity. A lower AIC value is generally preferred, implying that the `enhanced_model` is a better model choice from an information criterion standpoint.
- The BIC, like the AIC, is also lower for the `enhanced_model`. BIC, which includes a stricter penalty for the number of parameters, reinforces the conclusion drawn from the AIC: the additional complexity introduced by interaction terms does not lead to a proportional improvement in the model fit. BIC being more stringent, particularly in models with larger sample sizes and more parameters, suggests a strong preference for the simpler `enhanced_model`.
- Both AIC and BIC results point towards the `enhanced_model` as a more optimal balance between goodness of fit and parsimony. This indicates that, while interaction terms add detail and complexity to the model, they might not be contributing significantly to explaining the variability in your dependent variable.

### Logistic Regression Models Comparison (Odd Ratios and 95% Confidence Intervals)

```{r}
# Function to add significance asterisks
add_asterisks <- function(p_value) {
  if (is.na(p_value)) {
    return(NA)
  } else if (p_value < 0.001) {
    return("***")
  } else if (p_value < 0.01) {
    return("**")
  } else if (p_value < 0.05) {
    return("*")
  } else {
    return("")
  }
}
```

```{r}
# Function to format confidence intervals as a string
format_ci <- function(lower, upper) {
  paste0("(", round(lower, 2), ", ", round(upper, 2), ")")
}
```

```{r}
# Tidy the baseline model with confidence intervals
tidy_baseline <- tidy(baseline_model, conf.int = TRUE, exponentiate = TRUE)

# Tidy the enhanced model with confidence intervals
tidy_enhanced <- tidy(enhanced_model, conf.int = TRUE, exponentiate = TRUE)

# Tidy the interaction model with confidence intervals
tidy_interaction <- tidy(model_interaction, conf.int = TRUE, exponentiate = TRUE)
```

```{r}
# Apply the function to each model's p.value
tidy_baseline$asterisks <- sapply(tidy_baseline$p.value, add_asterisks)
tidy_enhanced$asterisks <- sapply(tidy_enhanced$p.value, add_asterisks)
tidy_interaction$asterisks <- sapply(tidy_interaction$p.value, add_asterisks)
```


```{r}
# Create OR strings with asterisks and format CIs as a string
tidy_baseline <- tidy_baseline %>%
  mutate(
    OR = ifelse(is.na(estimate), NA, paste0(round(estimate, 2), asterisks)),
    CI = ifelse(is.na(conf.low) | is.na(conf.high), NA, format_ci(conf.low, conf.high))
  )

tidy_enhanced <- tidy_enhanced %>%
  mutate(
    OR = ifelse(is.na(estimate), NA, paste0(round(estimate, 2), asterisks)),
    CI = ifelse(is.na(conf.low) | is.na(conf.high), NA, format_ci(conf.low, conf.high))
  )

tidy_interaction <- tidy_interaction %>%
  mutate(
    OR = ifelse(is.na(estimate), NA, paste0(round(estimate, 2), asterisks)),
    CI = ifelse(is.na(conf.low) | is.na(conf.high), NA, format_ci(conf.low, conf.high))
  )
```

```{r}
# Add a 'Model' column to each tidied dataframe
tidy_baseline <- tidy_baseline %>% mutate(Model = "Baseline")
tidy_enhanced <- tidy_enhanced %>% mutate(Model = "Enhanced")
tidy_interaction <- tidy_interaction %>% mutate(Model = "Interaction")

# Combine and pivot the dataframes
combined_results <- bind_rows(
  tidy_baseline %>% select(term, OR, CI, Model),
  tidy_enhanced %>% select(term, OR, CI, Model),
  tidy_interaction %>% select(term, OR, CI, Model)
) %>%
  pivot_wider(names_from = Model, values_from = c(OR, CI))
```

```{r}
# Replace NAs with "—"
combined_results[is.na(combined_results)] <- "—"
```

```{r}
# Reordering columns to have OR and CI next to each other for each model
combined_results <- combined_results %>%
  select(term, 
         OR_Baseline, CI_Baseline, 
         OR_Enhanced, CI_Enhanced, 
         OR_Interaction, CI_Interaction)
```


```{r}
# Print the final combined table
print(combined_results)
```


### Models Validation

#### Hosmer-Lemeshow Test

```{r}
# 1. Hosmer-Lemeshow Test for the Baseline Model
hoslem.test(baseline_model$y, fitted(baseline_model), g=10)

# 2. Hosmer-Lemeshow Test for the Enhanced Model (Baseline + Fixed Effects)
hoslem.test(enhanced_model$y, fitted(enhanced_model), g=10)

# 3. Hosmer-Lemeshow Test for the Interaction Model (Baseline + Fixed Effects + Interaction Terms)
hoslem.test(model_interaction$y, fitted(model_interaction), g=10)
```

A large p-value (>0.05) indicates a good fit, meaning that there's no significant difference between the observed and predicted values. Through each model, the p-value increases which suggests that our decision to include fixed effects and interaction terms are significant.


#### Likelihood Ratio Test (ANOVA)

```{r}
# Baseline vs. Baseline + Fixed Effects
anova(baseline_model, enhanced_model, test="Chisq")
```

The Enhanced Model provides a significantly better fit to the data compared to the Baseline Model, as indicated by the large decrease in residual deviance and the very small p-value (< 2.2e-16).


```{r}
# Baseline + Fixed Effects vs. Baseline + Fixed Effects + Interaction Terms
anova(enhanced_model, model_interaction, test="Chisq")
```

Adding the interaction terms between area and wealth_index does not significantly improve the model fit compared to the Enhanced Model without interaction terms. This is indicated by the relatively high p-value and the smaller decrease in residual deviance.

#### ROC Curve and AUC

```{r message=FALSE}
# For each model
roc_response_baseline <- roc(imputed_df$child_marriage, fitted(baseline_model))
auc_baseline <- auc(roc_response_baseline)

roc_response_enhanced <- roc(imputed_df$child_marriage, fitted(enhanced_model))
auc_enhanced <- auc(roc_response_enhanced)

roc_response_interaction <- roc(imputed_df$child_marriage, fitted(model_interaction))
auc_interaction <- auc(roc_response_interaction)

# Compare AUC values
print(paste("AUC Baseline Model:", auc_baseline))
print(paste("AUC Enhanced Model:", auc_enhanced))
print(paste("AUC Interaction Model:", auc_interaction))
```

1. Baseline Model (AUC: 0.7945):

The AUC value is close to 0.8, which indicates that the Baseline Model has good discriminative ability. In other words, it is capable of distinguishing between cases and controls with a high degree of accuracy.
An AUC of 0.5 represents a model with no discriminative ability (akin to random guessing), while an AUC of 1.0 represents perfect discrimination. So, my model is performing substantially better than random guessing.

2. Enhanced Model (AUC: 0.8093):

This model shows a slight improvement in AUC over the Baseline Model. The increase suggests that the additional variables (or adjustments) you made in the Enhanced Model contribute positively to its ability to differentiate between cases and controls.
The difference in AUC between the Baseline and Enhanced models, while modest, is still meaningful, especially in practical, real-world contexts.

3. Interaction Model (AUC: 0.8099):

The Interaction Model shows a very slight improvement in AUC over the Enhanced Model. This indicates that adding interaction terms provides a marginal improvement in the model's discriminatory power.
However, the improvement is very minimal, which aligns with my earlier findings that the interaction terms did not significantly improve the model fit.

4. Overall:

All models demonstrate good ability to distinguish between cases and controls. An AUC greater than 0.7 is generally considered acceptable, and my models are around or above 0.8.
The Enhanced and Interaction Models only show marginal improvements in AUC compared to the Baseline Model. This suggests that while the additional complexity (more variables and interaction terms) does contribute slightly to model performance, the gains are not substantial.
Given the slight increases in AUC with added model complexity, consider the trade-offs. A simpler model might be preferable if it is easier to interpret and communicate, especially if the increase in predictive power is minimal. Personally, given this result, I think Enhanced Model might be a better-suited model overall.


### Gut Check: Redo Analysis with Actual Data (no imputation)

#### Recreate the dataframe with removed missing data

```{r}
# No imputation -- Remove rows with any missing data from 'female_df'
og_df <- na.omit(female_df)
head(og_df)
```

#### Recreate necessary variables

```{r}
# Convert "age at first marriage" into a binary variable to indicate child marriage
# Child marriage is defined as marriage before the age of 18
# The new binary variable "child_marriage" will have a value of 1 if the marriage occurred before age 18, and 0 otherwise
og_df <- og_df %>%
  mutate(child_marriage = ifelse(age_first_marriage < 18, 1, 0))
```

```{r}
# Create a binary variable for child marriage under 16
# The new variable "child_marriage_u16" will have a value of 1 if the marriage occurred before age 16, and 0 otherwise
og_df <- og_df %>%
  mutate(child_marriage_u16 = ifelse(age_first_marriage < 16, 1, 0))
```

```{r}
# Move "child_marriage" and "child_marriage_u16" to the front of the dataframe
og_df <- og_df %>%
  select(child_marriage, child_marriage_u16, everything())
```

#### Converting Categorical and Binary Variables to Factors

```{r}
# Convert nominal and ordinal variables to factors
og_df$area <- as.factor(og_df$area)
og_df$region <- as.factor(og_df$region)
og_df$education_level <- factor(og_df$education_level, ordered = FALSE)
og_df$ethnicity <- as.factor(og_df$ethnicity)
og_df$wealth_index <- factor(og_df$wealth_index, ordered = FALSE)

# Binary variables are already in the correct format and can be used as is
```

#### Recreate the regression models without imputed data

```{r}
# Base model
base_model_no_impute <- glm(child_marriage ~ area + education_level + wealth_index + health_insurance + current_contraceptive_use + awareness_hiv_aids + access_to_media, family = binomial(), data = og_df)

# Summarize the base model
summary(base_model_no_impute)
```


```{r}
# Enhanced model with additional fixed effects
enhanced_model_no_impute <- glm(child_marriage ~ area + region + education_level + ethnicity + wealth_index + health_insurance + current_contraceptive_use + awareness_hiv_aids + access_to_media, family = binomial(), data = og_df)

# Summarize the new model with FEs
summary(enhanced_model_no_impute)
```


#### Assessing AICs and BICs of Base Model vs Fixed Effects Model

```{r}
# Model comparison using AIC
aic_base <- AIC(base_model_no_impute)
aic_enhanced <- AIC(enhanced_model_no_impute)
cat("AIC - Base Model:", aic_base, "\n")
cat("AIC - Enhanced Model:", aic_enhanced, "\n")
```

Additionally, the lower AIC for the model with two fixed effects compared to the baseline model suggests that adding these fixed effects improves the model's overall fit. This aligns with my theoretical justification for including region and ethnicity as relevant factors in predicting child marriage.

```{r}
# Model comparison using BIC
bic_base <- BIC(base_model_no_impute)
bic_enhanced <- BIC(enhanced_model_no_impute)
cat("BIC - Base Model:", bic_base, "\n")
cat("BIC - Enhanced Model:", bic_enhanced, "\n")
```

Lower BIC values suggest that, despite the added complexity (more parameters), the model with both region and ethnicity provides a better overall fit to my data when adjusted for the number of predictors. This is a strong indication that these variables are meaningful in explaining the variance in child marriage occurrences in my dataset.


### Model with Interaction Terms (Area:Wealth_Index)

```{r}
# Adding the interaction term between education level and wealth index
interaction_model_no_impute <- update(enhanced_model_no_impute, . ~ . + area:wealth_index)
summary(interaction_model_no_impute)
```

```{r}
cat("AIC (enhanced):", AIC(enhanced_model_no_impute), "\nAIC (w/ interaction terms):", AIC(interaction_model_no_impute), "\n")
cat("BIC (enhanced):", BIC(enhanced_model_no_impute), "\nBIC (w/ interaction terms):", BIC(interaction_model_no_impute), "\n")
```
- The AIC and BIC results for my two models – the `enhanced_model_no_impute` and `interaction_model_no_impute` – indicate that the simpler model (without interaction terms) has a better trade-off between model fit and complexity.
- The AIC is lower for the enhanced_model_no_impute compared to the `interaction_model_no_impute`. This suggests that, despite possibly having a good fit, the addition of interaction terms to the `interaction_model_no_impute` does not improve the model's performance enough to justify the added complexity. A lower AIC value is generally preferred, implying that the `enhanced_model_no_impute` is a better model choice from an information criterion standpoint.
- The BIC, like the AIC, is also lower for the `enhanced_model_no_impute`. BIC, which includes a stricter penalty for the number of parameters, reinforces the conclusion drawn from the AIC: the additional complexity introduced by interaction terms does not lead to a proportional improvement in the model fit. BIC being more stringent, particularly in models with larger sample sizes and more parameters, suggests a strong preference for the simpler `enhanced_model_no_impute`.
- Both AIC and BIC results point towards the `enhanced_model_no_impute` as a more optimal balance between goodness of fit and parsimony. This indicates that, while interaction terms add detail and complexity to the model, they might not be contributing significantly to explaining the variability in your dependent variable.

```{r}
# VIFs check (A VIF value > 5 indicates high multicollinearity)
# Base model
base_no_impute_vif <- vif(base_model_no_impute)
print(base_no_impute_vif)

# Enhanced model
enhanced_no_impute_vif <- vif(enhanced_model_no_impute)
print(enhanced_no_impute_vif)

# Interacton model
interaction_no_impute_vif <- vif(interaction_model_no_impute)
print(interaction_no_impute_vif)
```

- Most VIF values are just slightly above 1, which indicates no concerning multicollinearity in this model.
- Except for `wealth_index` and `area:wealth_index`, their VIF values are significantly higher (around 2.17 and 2.16, respectively). These values suggest a considerable level of multicollinearity, which is often expected when including interaction terms in a model.
- High multicollinearity in models, especially those with interaction terms, doesn't invalidate the model but does complicate the interpretation of specific coefficients. 


#### Comparing Models With vs Without Imputed Data

```{r}
# Extracting data from the models
extract_model_data <- function(model) {
  model_summary <- summary(model)
  coeffs <- model_summary$coefficients
  data.frame(
    Term = rownames(coeffs),
    Estimate = sprintf("%.3f", coeffs[, "Estimate"]),
    pValue = ifelse(coeffs[, "Pr(>|z|)"] < 0.001, 
                    format(coeffs[, "Pr(>|z|)"], scientific = TRUE),
                    sprintf("%.3f", coeffs[, "Pr(>|z|)"])),
    Significance = sapply(coeffs[, "Pr(>|z|)"], add_asterisks)
  )
}
```


```{r}
# Applying the function to each model
base_impute_data <- extract_model_data(baseline_model)
base_no_impute_data <- extract_model_data(base_model_no_impute)

# Combine the data for comparison
base_comparison_data <- merge(base_impute_data, base_no_impute_data, by = "Term", suffixes = c("_Impute", "_NoImpute"), sort = FALSE)

# View the comparison
print(base_comparison_data)
```

- Education and Wealth Index variables are consistent, robust and significant predictors of the outcome across both models.
- For some variables like 'current contraceptive use', imputation significantly impacts its role in the model. It could indicate the missing data mechanism's influence.
- Significance of Area: This variable's significance suggests geographical variation is an important factor, but its influence is reduced in the non-imputed model.
- The overall patterns suggest that while some predictors are consistently influential, others are sensitive to how missing data is handled.


```{r}
# Applying the function to each model
enhanced_impute_data <- extract_model_data(enhanced_model)
enhanced_no_impute_data <- extract_model_data(enhanced_model_no_impute)

# Combine the data for comparison
enhanced_comparison_data <- merge(enhanced_impute_data, enhanced_no_impute_data, by = "Term", suffixes = c("_Impute", "_NoImpute"), sort = FALSE)

# View the comparison
print(enhanced_comparison_data)
```

- Education levels and ethnicity (specific categories) are robust across both models.
- Certain variables like area, region, and wealth index are sensitive to imputation, suggesting that missing data in these areas could be informative.
- The loss of significance in many variables in the non-imputed model suggests that the missing data may not be random and could be related to the variables' influence on the outcome.


```{r}
# Applying the function to each model
interaction_impute_data <- extract_model_data(model_interaction)
interaction_no_impute_data <- extract_model_data(interaction_model_no_impute)

# Combine the data for comparison
interaction_comparison_data <- merge(interaction_impute_data, interaction_no_impute_data, by = "Term", suffixes = c("_Impute", "_NoImpute"), sort = FALSE)

# View the comparison
print(interaction_comparison_data)
```

- The effects of imputation are most pronounced in geographical variables (area and region) and some interactions, indicating a potential non-random pattern in how missing data occurs in these variables.
- Certain variables like higher education levels and some ethnicity categories maintain their predictive power regardless of missing data imputation, indicating a stronger and more consistent relationship with the outcome.

